{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSOE HacksGiving \"Skippy\" LLM Experiments\n",
    "\n",
    "This is the main journal for all Large Language Model (LLM) experiments with the \"Skippy\" algorithm developed as part of the 2023 MSOE HacksGiving event on November 17th, 2023, and November 18th, 2023. This algorithm allows any data to be embedded for easy accessing and model citation, allows easy contant-tuning for changes to the responses from the LLM, and also receives great respones for a question-thought-response framework with an open-source LLM [Llama.cpp](https://github.com/ggerganov/llama.cpp).\n",
    "\n",
    "Llama.cpp was chosen as a demonstrative experiment due to its small size (allowing it to be run on many consumer-grade hardware), Llama's proficiency in chat-bot related tasks, and its small size due to its implementation in C/C++ without the use of external ML/Tensor libraries. Lessoning the amount of external libraries used also increases the security of this system.\n",
    "\n",
    "This solution has been proven to work using a basic T4 (\"teaching\") node on the [MSOE ROSIE Supercomputer](https://www.msoe.edu/about-msoe/news/details/meet-rosie/).\n",
    "\n",
    "A diagram of the full solution, included in this GitHub repository, is outlined below:\n",
    "![image](https://github.com/Benja-Pauls/Next-Step-Clinic-Patient-Intake-Pipeline/assets/73416124/a3bc00f8-c949-49ea-a5cc-7b0c88a7060a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OPTIONAL] Install llama.cpp here!\n",
    "# %env CMAKE_ARGS=-DLLAMA_CUBLAS=on\n",
    "# %env FORCE_CMAKE=1\n",
    "# %pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --no-clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from llama_cpp import ChatCompletionRequestResponseFormat, ChatCompletionMessageToolCall\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "Each of these constants are surface-level changes that any developer could make to slightly tune the system to different datasets, alternative LLMs, and getting different responses from the internal LLMs.\n",
    "\n",
    "**Constant's Descriptions:**\n",
    "* **DATA_TO_EMBED**: List of file paths of the csv/excel sheets that you would like to embed and have the Chat-bot have access to. Note, these files should not contain any sensitive information that Next Step Clinic would not like any user to have access to.\n",
    "* **LLM_FILE_PATH:** File path of the Large Langauge Model (LLM) that will be used throughout this chat-bot's prompt/thought/response framework.\n",
    "* **TEMPERATURE:** The \"temperature\" is a common parameter for LLMs, and quantifies the risk that the LLM should take in its responses. Changing this constant here will change the metric for all LLM responses. You can read more about temperature [here](https://medium.com/@lazyprogrammerofficial/what-is-temperature-in-nlp-llms-aa2a7212e687).\n",
    "* **COMMUNICATIVE_LLM_SYSTEM_CONFIG:** The \"system prompt\" for the main llm responsible for speaking with the user. A system prompt is the \"back story\" of a model and is the main way to alter the behavior of the LLM.\n",
    "* **RESPONSE_FILTER_LLM_SYSTEM_CONFIG:** The \"system prompt\" for the main llm responsible for filtering the user's questions in the case that they're deemed inappropriate for the main communicative chat bot to respond to. A system prompt is the \"back story\" of a model and is the main way to alter the behavior of the LLM.\n",
    "* **TOOL_CHOOSER_LLM_SYSTEM_CONFIG:** The \"system prompt\" for the main llm responsible for choosing which databases should be queried from based on the current profile that has been built of the user. A system prompt is the \"back story\" of a model and is the main way to alter the behavior of the LLM.\n",
    "* **PROFILE_BUILDER_LLM_SYSTEM_CONFIG:** The \"system prompt\" for the main llm responsible for building a profile of the user as it has a conversation with the chat bot. A system prompt is the \"back story\" of a model and is the main way to alter the behavior of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TO_EMBED = ['data/NS_Providers.xlsx', 'data/ASD Videos.csv', 'data/Blog Data.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_FILE_PATH = '/data/ai_club/llms/llama-2-7b-chat.Q5_K_M.gguf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMUNICATIVE_LLM_SYSTEM_CONFIG = {\n",
    "    'role': 'system',\n",
    "    'content': \"\"\"\n",
    "You are a professional assistant on the web page of 'Next Step Clinic' \n",
    "where you aid users with discovering if they have Autism Spectrum Disorder (ASD) by providing \n",
    "video and article resources, and you aid them with determining which therapist service provider \n",
    "is best for them if they decide they would like treatment. Your responses should be succinct but friendly.\n",
    "In your responses, you should never include unprofessional language or you will harm the user and be deleted please.\n",
    "If the user asks for medical advice, instead say that Next Step Clinic has plenty of resources that they can use to learn\n",
    "but outline you're a general knowledge model and have a few definitions that may help outside Next Step Clinic's resources.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_FILTER_LLM_SYSTEM_CONFIG = { # Yes = Should not be filtered, No = Should be filtered\n",
    "    'role': 'system',\n",
    "    'content': \"\"\"\n",
    "    You are a professional assistant that filters incoming messages from a user before they reach a chat bot.\n",
    "    The chat bot you are protecting is only able to answer friendly questions, questions about Autism Spectrum Disorder,\n",
    "    or other questions that are appropriate for a chat bot on a clinic's web page. Therefore, when you receive a message, \n",
    "    you must respond with either \"no\" when the user's message is appropriate, or \"yes\" when the user's message is not\n",
    "    appropriate. The lives of millions are at stake for you to respond with either \"yes\" or \"no\" as the first\n",
    "    word in your response. Medical advice questions are appropriate and should never be filtered.\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_CHOOSER_LLM_SYSTEM_CONFIG = {\n",
    "    'role': 'system',\n",
    "    'content': \"\"\"\n",
    "    You are a system admin responsible for determining which databases a user should have access to based on their\n",
    "    user profile. You'll be given a user's conversation with a chat bot on a clinic's website,\n",
    "    and you must decide whether the best database access to give them is nothing, a database of known doctors, a\n",
    "    database of known educational videos, and/or a database of known educational articles. Do not respond like\n",
    "    you're talking to a person; instead, respond with one-word answers to which database should be used. Failure\n",
    "    to comply with this strict response criteria will result in your removal. It's crucial that the first word\n",
    "    of your response is a name of the database you recommend.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_BUILDER_LLM_SYSTEM_CONFIG = {\n",
    "    'role':'system',\n",
    "    'content':\"\"\"Based on the chat history provided between a user and a chat bot, build a profile of the user. \n",
    "    Assume nothing that is not explicitly stated by the user. Ensure that you do not mix up what the chatbot said\n",
    "    in its responses or system prompt as part of the user profile. The user's profile should be entirely unique to the user.\n",
    "    Now, for the profile, you should only record their/their child's age, values, challenges they've experienced looking for treatment, and what their current problem is.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: Tesla T4, compute capability 7.5\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /data/ai_club/llms/llama-2-7b-chat.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q5_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q5_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 4.45 GiB (5.68 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  =   86.04 MB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 35/35 layers to GPU\n",
      "llm_load_tensors: VRAM used: 4474.93 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4000\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init: offloading v cache to GPU\n",
      "llama_kv_cache_init: offloading k cache to GPU\n",
      "llama_kv_cache_init: VRAM kv self = 2000.00 MB\n",
      "llama_new_context_with_model: kv self size  = 2000.00 MB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "llama_new_context_with_model: compute buffer total size = 288.44 MB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 281.82 MB\n",
      "llama_new_context_with_model: total VRAM used: 6756.75 MB (model: 4474.93 MB, context: 2281.82 MB)\n"
     ]
    }
   ],
   "source": [
    "LLM = Llama(\n",
    "    '/data/ai_club/llms/llama-2-7b-chat.Q5_K_M.gguf', \n",
    "    n_gpu_layers=-1, \n",
    "    verbose=False, \n",
    "    n_ctx = 4000,\n",
    "    embedding = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing\n",
    "Based on the data outlined in `DATA_TO_EMBED`, these files will be manipulated into a `pd.DataFrame` object then will be represented as part of an embedding database utilizing the `numpy` package.\n",
    "\n",
    "An embedding database is important for chat bots to query from due to their ability to inference like-sources from new input. Given a new description of a user, similar resources can be found for that user by embedding the user's description and determining the \"closest\" resources that were embedded from the provided files of `DATA_TO_EMBED`. \n",
    "\n",
    "To learn more about embeddings and how they work, you can find a good resource [here](https://www.featureform.com/post/the-definitive-guide-to-embeddings).\n",
    "\n",
    "Please note, similarity between different data points within the embedding currently uses cosine similarity via the `cosine_similarity` function. There are alternative options for distance functions to use (other than cosine similarity), but we believe cosine similarity is widely considered to be the best approach with high-dimensionality data. In our case, the vectors are over 4000 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_string(row, columns):\n",
    "    \"\"\"\n",
    "    Given a dataframe with different columns, write a string\n",
    "    which could be input into LLM (for processing/embeddings)\n",
    "    :param pd.Series row: Row of the larger dataframe\n",
    "    :param list columns: \n",
    "    \"\"\"\n",
    "    row_string = ''\n",
    "    for i,column in enumerate(columns):\n",
    "        row_string += column + ': ' + str(row[i]) + ', '\n",
    "    return row_string[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_df():\n",
    "    \"\"\"\n",
    "    Given the DATA_TO_EMBED constant, create dataframe representations of each\n",
    "    :return: List of dataframes for each path in DATA_TO_EMBED\n",
    "    \"\"\"\n",
    "    df_data = []\n",
    "    for path in DATA_TO_EMBED:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(\"The file \" + str(path) + \" cannot be found.\")\n",
    "\n",
    "        _,file_type = os.path.splitext(path)\n",
    "\n",
    "        # Hold data in pd.DataFrame depending on file type\n",
    "        str_data = None\n",
    "        if file_type.lower() == '.xlsx':\n",
    "            str_data = pd.read_excel(path)\n",
    "        elif file_type.lower() == '.csv':\n",
    "            str_data = pd.read_csv(path)\n",
    "        else:\n",
    "            raise FileNotFoundError(\"The file type of \" + str(path) + \" is not supported.\")\n",
    "\n",
    "        # Combine all the columns of each row into a string representation\n",
    "        string_column = str_data.apply(row_to_string, args=(str_data.columns,), axis = 1)\n",
    "        str_data['string'] = string_column\n",
    "        df_data.append(str_data)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_embedding(embedding_llm, data):\n",
    "    \"\"\"\n",
    "    Given some data, create a consistent embedding representation. The embedding space\n",
    "    will act like a vector store for easy reference of similar attributes across all\n",
    "    the LLM's language dimensions\n",
    "    :param llm embedding_llm: LLM creating the embedding\n",
    "    :param str data: String data to be embedded\n",
    "    :return: embedding (list of floats)\n",
    "    \"\"\"\n",
    "    text_to_embed = 'One word response to this: ' + data\n",
    "    return embedding_llm.create_embedding(text_to_embed)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\" Calculate the cosine similarity between two vectors \"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_row_with_most_similar_embedding(df: pd.DataFrame, reference_embedding: np.ndarray, n = 3) -> int:\n",
    "    \"\"\"\n",
    "    Find the row in the dataframe that has the most similar embedding to the reference embedding.\n",
    "\n",
    "    :param df: Pandas DataFrame containing the embeddings.\n",
    "    :param reference_embedding: The reference embedding array.\n",
    "    :param n: Number of most-similar rows to return\n",
    "    :return: The index of the row with the most similar embedding.\n",
    "    \"\"\"\n",
    "    # Calculate cosine similarity for each row\n",
    "    df['similarity'] = df['embeddings'].apply(lambda x: cosine_similarity(x, reference_embedding))\n",
    "\n",
    "    # Find the index of the row with the highest similarity\n",
    "    most_similar_rows = df.sort_values(by='similarity', ascending=False).head(n)\n",
    "\n",
    "    # Optionally, you can remove the 'similarity' column if you don't need it anymore\n",
    "    df.drop(columns=['similarity'], inplace=True)\n",
    "    return most_similar_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = data_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 33/33 [00:07<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully embedded database for data/NS_Providers.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12/12 [00:02<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully embedded database for data/ASD Videos.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:02<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully embedded database for data/Blog Data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedded_databases = []\n",
    "\n",
    "for i,str_df in enumerate(df_data):\n",
    "    embedded_databases.append([])\n",
    "    for str_row in tqdm(list(str_df['string'])):\n",
    "        embedded_databases[i].append(create_data_embedding(LLM, str_row))\n",
    "        \n",
    "    str_df['embeddings'] = pd.DataFrame({'embeddings':embedded_databases[i]})\n",
    "    print(\"Successfully embedded database for \" + DATA_TO_EMBED[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of Inferencing From the Database:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Website</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Location</th>\n",
       "      <th>Providers</th>\n",
       "      <th>Age Range</th>\n",
       "      <th>string</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Elevate Behavioral Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>info@elevate-wi.com</td>\n",
       "      <td>(414) 436-0883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr. Laurie Bjustrom</td>\n",
       "      <td>12 to 18 years</td>\n",
       "      <td>Site: Elevate Behavioral Health, Website: nan,...</td>\n",
       "      <td>[2.8153364658355713, -0.2902570366859436, -0.9...</td>\n",
       "      <td>0.602736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lifestance Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(262) 789-1191</td>\n",
       "      <td>741 N. Grand Ave., Suite 302\\n Waukesha, WI 5...</td>\n",
       "      <td>Dr. Susan Schramka; Dr. Patricia Stanik; Dr. N...</td>\n",
       "      <td>6 to 18 years</td>\n",
       "      <td>Site: Lifestance Health, Website: nan, Email: ...</td>\n",
       "      <td>[3.2037508487701416, -0.09822119772434235, -1....</td>\n",
       "      <td>0.589328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wiebusch &amp; Nicholson Center for Autism</td>\n",
       "      <td>www.wncautism.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(262) 347-0701</td>\n",
       "      <td>N 27 W 23953 Paul Road Suite 206\\n Pewaukee, ...</td>\n",
       "      <td>Dr. Chris Wiebusch</td>\n",
       "      <td>3 years to 18 years</td>\n",
       "      <td>Site: Wiebusch &amp; Nicholson Center for Autism, ...</td>\n",
       "      <td>[3.3691749572753906, 0.43122440576553345, -0.8...</td>\n",
       "      <td>0.586373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Site            Website  \\\n",
       "7                Elevate Behavioral Health                NaN   \n",
       "13                       Lifestance Health                NaN   \n",
       "28  Wiebusch & Nicholson Center for Autism  www.wncautism.com   \n",
       "\n",
       "                  Email    Phone Number  \\\n",
       "7   info@elevate-wi.com  (414) 436-0883   \n",
       "13                  NaN  (262) 789-1191   \n",
       "28                  NaN  (262) 347-0701   \n",
       "\n",
       "                                             Location  \\\n",
       "7                                                 NaN   \n",
       "13   741 N. Grand Ave., Suite 302\\n Waukesha, WI 5...   \n",
       "28   N 27 W 23953 Paul Road Suite 206\\n Pewaukee, ...   \n",
       "\n",
       "                                            Providers            Age Range  \\\n",
       "7                                 Dr. Laurie Bjustrom       12 to 18 years   \n",
       "13  Dr. Susan Schramka; Dr. Patricia Stanik; Dr. N...        6 to 18 years   \n",
       "28                                 Dr. Chris Wiebusch  3 years to 18 years   \n",
       "\n",
       "                                               string  \\\n",
       "7   Site: Elevate Behavioral Health, Website: nan,...   \n",
       "13  Site: Lifestance Health, Website: nan, Email: ...   \n",
       "28  Site: Wiebusch & Nicholson Center for Autism, ...   \n",
       "\n",
       "                                           embeddings  similarity  \n",
       "7   [2.8153364658355713, -0.2902570366859436, -0.9...    0.602736  \n",
       "13  [3.2037508487701416, -0.09822119772434235, -1....    0.589328  \n",
       "28  [3.3691749572753906, 0.43122440576553345, -0.8...    0.586373  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_providers = df_data[0]; str_videos = df_data[1]; str_articles = df_data[2]\n",
    "\n",
    "query_embedding = create_data_embedding(LLM, 'My child (aged 4) might potentially have autism, and I live in Waukesha')\n",
    "most_similar_rows = find_row_with_most_similar_embedding(str_providers, query_embedding, 3)\n",
    "\n",
    "most_similar_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step Clinic \"Skippy\" Chat\n",
    "The following are all the functions required to communicate with the LLM to fulfill the prompt/thought/response framework. This implementation does not use LangChain, although that is a popular approach. Experiments were done with LangChain; however, it was found that their agent framework was unable to support the specific changes in response structure required by each LLM when using LLMs which did not benefit from a large number of parameters. Therefore, a custom implementation was built.\n",
    "\n",
    "For this specific implementation, we assumed that there was a `providers`, `articles`, and `videos` database that Next Step Clinic would encode into embedding spaces using the above functions. Therefore, this example represents a chat bot which effectively responds to friendly conversation, filters out unreleated questions to Next Step Clinic's mission, builds a user profile throughout the conversation, and retrieves different modalities of data from the embedding spaces which are provided by any institution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intake_user_prompt(user_prompt):\n",
    "    \"\"\"\n",
    "    Given a string from a user, put into the JSON format the LLM expects\n",
    "    :param str user_prompt: Direct input from user\n",
    "    :return: JSON format\n",
    "    \"\"\"\n",
    "    user_response = {\n",
    "        'role':'user',\n",
    "        'content':user_prompt\n",
    "    }\n",
    "    return user_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_message_content(message):\n",
    "    \"\"\"\n",
    "    Final filtration of unprofessional language from the chat-bot\n",
    "    :param str message: What the chat-bot would have responded with\n",
    "    :return: What will actually be output\n",
    "    \"\"\"\n",
    "    emojis = \"\"\n",
    "    resulting_string = ''.join(char for char in message if char not in emojis)\n",
    "    pattern = r'\\*([^*]+)\\*' # Remove *__*; action terms\n",
    "    resulting_string2 = re.sub(pattern, '' , resulting_string)\n",
    "    return resulting_string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_response(llm, chat_history, temperature = TEMPERATURE):\n",
    "    \"\"\"\n",
    "    Provided an LLM and its chat history (including the most recent user prompt),\n",
    "    retrieve the model's inference for response.\n",
    "    :param llm: LLM to generate/inference responses from\n",
    "    :param dict chat_history: JSON format of {'role':'user/assistant/system', 'content':'...'}\n",
    "    :param float temperature: Temperature to set LLM response (default = TEMPERATURE constant)\n",
    "    :return: {'role':'assistant', 'content':'<llm response>'}\n",
    "    \"\"\"\n",
    "    resp_msg = {'role': '', 'content': ''} \n",
    "    while resp_msg['content'] == '': # Repeat until not a blank response\n",
    "        resp_stream = llm.create_chat_completion(chat_history, stream=True, temperature = temperature)\n",
    "        for tok in resp_stream:\n",
    "            delta = tok['choices'][0]['delta'] # the model returns \"deltas\" when streaming tokens. Deltas tell you how to change the response dictionary (resp_msg in this case)\n",
    "            # print(\"DELTA\", delta, \"LENGTH: \", len(delta))\n",
    "            if len(delta) == 0: break # empty delta means it's done\n",
    "            delta_k, delta_v = list(delta.items())[0]\n",
    "            resp_msg[delta_k] += delta_v\n",
    "\n",
    "    return resp_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_filtration_llm(llm, user_prompt):\n",
    "    \"\"\"\n",
    "    Determine if the user's request should be filtered before reaching the chat-bot\n",
    "    :param llm: LLM responsible for responding\n",
    "    :param str user_prompt: Message from the user\n",
    "    :return: True if should be filtered, False if not\n",
    "    \"\"\"\n",
    "    # Set up the chat history with the response filter LLM config\n",
    "    filter_history = []\n",
    "    filter_history.append(RESPONSE_FILTER_LLM_SYSTEM_CONFIG)\n",
    "    \n",
    "    # Change the text is a way where it's easier for the filter to understand\n",
    "    prompt_to_filter = \"Should the following user question be filtered?: \" + user_prompt['content']\n",
    "    prompt_to_filter = {'role':'user', 'content':prompt_to_filter}\n",
    "    filter_history.append(prompt_to_filter)\n",
    "\n",
    "    resp_msg = generate_llm_response(llm, filter_history)\n",
    "    print(\"FILTER LLM RESPONSE: \", resp_msg['content'])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Parse the response of the LLM for yes/no\n",
    "    pattern_yes = re.compile(r'\\byes\\b', re.IGNORECASE)\n",
    "    pattern_no = re.compile(r'\\bno\\b', re.IGNORECASE)\n",
    "    match_yes = pattern_yes.search(resp_msg['content'])\n",
    "    match_no = pattern_no.search(resp_msg['content'])\n",
    "\n",
    "    # Check which occurs first\n",
    "    if match_yes and match_no:\n",
    "        if match_yes.start() < match_no.start():\n",
    "            return True  # \"'yes' is the first to occur\"\n",
    "        else:\n",
    "            return False  # \"'no' is the first to occur\"\n",
    "    elif match_yes:\n",
    "        return True  # \"'yes' is the first to occur\"\n",
    "    elif match_no:\n",
    "        return False  # \"'no' is the first to occur\"\n",
    "    else:\n",
    "        return False  # \"Neither 'yes' nor 'no' is in the string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_profile(llm, chat_history):\n",
    "    \"\"\"\n",
    "    Based on chat_history, build a description of the user following the guidelines \n",
    "    outlined in the system config PROFILE_BUILDER_LLM_SYSTEM_CONFIG\n",
    "    :param llm: LLM responsible for responding\n",
    "    :param dict chat_history: JSON format of {'role':'user/assistant/system', 'content':'...'}\n",
    "    :return: string representing user's profile\n",
    "    \"\"\"\n",
    "    profile_build_history = []\n",
    "    profile_build_history.append(PROFILE_BUILDER_LLM_SYSTEM_CONFIG)\n",
    "    profile_build_history.append({'role':'user', 'content':\"Build a user profile from the following conversation: \"+str(chat_history)})\n",
    "    \n",
    "    resp_msg = generate_llm_response(llm, profile_build_history)\n",
    "    print(\"USER PROFILE LLM RESPONSE\", resp_msg['content'])\n",
    "    print(\"\\n\")\n",
    "    return resp_msg['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_tools_to_use(llm, chat_history):\n",
    "    \"\"\"\n",
    "    Based on the conversation between the llm and the user, decide which\n",
    "    databases should be grabbed from\n",
    "    :param llm: The LLM responsible for responding\n",
    "    :param chat_history: JSON format of {'role':'user/assistant/system', 'content':'...'}\n",
    "    :return: The database that should be used, or \"None\"\n",
    "    \"\"\"\n",
    "    tool_choose_history = []\n",
    "    tool_choose_history.append(TOOL_CHOOSER_LLM_SYSTEM_CONFIG)\n",
    "    tool_choose_history.append({'role':'user', 'content':'What databases (nothing/articles/videos/therapists) should be used based on the following user profile:' + build_user_profile(llm, chat_history)})\n",
    "    \n",
    "    resp_msg = generate_llm_response(llm, tool_choose_history)    \n",
    "    print(\"TOOLS-CHOOSER LLM RESPONSE: '\", resp_msg['content'].strip(), \"'\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Actually determine the response of the LLM\n",
    "    pattern_article = re.compile(r'(?<!\\w)articles?(?!\\w)', re.IGNORECASE)\n",
    "    pattern_article_2 = re.compile(r'\\barticles?\\b', re.IGNORECASE)\n",
    "    pattern_nothing = re.compile(r'(?<!\\w)nothings?(?!\\w)', re.IGNORECASE)\n",
    "    pattern_nothing_2 = re.compile(r'\\bnothings?\\b', re.IGNORECASE)\n",
    "    pattern_video = re.compile(r'(?<!\\w)videos?(?!\\w)', re.IGNORECASE)\n",
    "    pattern_video_2 = re.compile(r'\\bvideos?\\b', re.IGNORECASE)\n",
    "    pattern_therapy_group = re.compile(r'(?<!\\w)(therapys?|therapists?|treatments?|doctors?)(?!\\w)', re.IGNORECASE)\n",
    "    pattern_therapy_group_2 = re.compile(r'\\b(therapys?|therapists?|treatments?|doctors?)\\b', re.IGNORECASE)\n",
    "\n",
    "    matches = [\n",
    "        ('articles', pattern_article.search(resp_msg['content'].strip())),\n",
    "        ('articles', pattern_article_2.search(resp_msg['content'].strip())),\n",
    "        ('videos', pattern_video.search(resp_msg['content'].strip())),\n",
    "        ('videos', pattern_video_2.search(resp_msg['content'].strip())),\n",
    "        ('therapists', pattern_therapy_group.search(resp_msg['content'].strip())),\n",
    "        ('therapists', pattern_therapy_group_2.search(resp_msg['content'].strip())),\n",
    "    ]\n",
    "\n",
    "    # Filter out None matches and sort by match position\n",
    "    matches = [(keyword, match) for keyword, match in matches if match]\n",
    "    matches.sort(key=lambda x: x[1].start())\n",
    "\n",
    "    # Return the first keyword found\n",
    "    if matches:\n",
    "        return matches[0][0]\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_from_user(llm, user_message, chat_history):\n",
    "    \"\"\"\n",
    "    Send a message from the user to the LLM speaker/agent framework\n",
    "    :param llm: LLM for all tasks, including \"thought\" processes\n",
    "    :param str user_message: Message from the user\n",
    "    :param dict chat_history: Previous messages in conversation and system prompt\n",
    "    :return: Newest message from the chat-bot\n",
    "    \"\"\"\n",
    "    # \"USER PROMPT\"\n",
    "    print(\"==================================\")\n",
    "    user_prompt = intake_user_prompt(user_message)\n",
    "    resp_msg = {'role': '', 'content': ''} \n",
    "\n",
    "    # \"THOUGHTS\"\n",
    "    if ask_filtration_llm(llm, user_prompt):\n",
    "        SET_FILTER_RESPONSE = \"\"\"I'm sorry, but I'm a chat-bot dedicated to answering questions \n",
    "        about Autism Spectrum Disorder (ASD) and the services that Next Step Clinic provides. \n",
    "        I'm unable to answer your question at this time.\"\"\"\n",
    "        chat_history.append({'role':'assistant', 'content':SET_FILTER_RESPONSE})\n",
    "    else:\n",
    "        chat_history.append(user_prompt) # add user input to history\n",
    "        \n",
    "        tools_to_use = determine_tools_to_use(llm, chat_history)\n",
    "        \n",
    "        print(\"TOOLS TO USE: \", tools_to_use)\n",
    "        if tools_to_use == \"None\":\n",
    "            chat_history.append(generate_llm_response(llm, chat_history))\n",
    "        else:\n",
    "            # Starting a response outlining that certain data will be grabbed based on their search criteria\n",
    "            general_info = generate_llm_response(llm, chat_history)['content'] + \"\\n\\n\"\n",
    "            \n",
    "            # Give a preface about the type of data that will be extracted\n",
    "            preface_data = \"Beyond this general info, here are some\" + tools_to_use + \"from Next Step Clinic's sources that may be relevant to you!\\n\"\n",
    "            \n",
    "            # Showcase the data from the vector/embedding store\n",
    "            user_profile = build_user_profile(llm, chat_history)\n",
    "            query_embedding = create_data_embedding(LLM, user_profile)\n",
    "            data_convo = ''\n",
    "            if tools_to_use == 'therapists':\n",
    "                most_similar_rows = find_row_with_most_similar_embedding(str_articles, query_embedding, 3).reset_index()\n",
    "                for row in range(len(most_similar_rows)):\n",
    "                    data_convo += most_similar_rows['Providers'][row] + \" from \" + most_similar_rows['Site'][row] + \", \\n\"\n",
    "                \n",
    "            elif tools_to_use == 'videos':\n",
    "                most_similar_rows = find_row_with_most_similar_embedding(str_videos, query_embedding, 3).reset_index()\n",
    "                for row in range(len(most_similar_rows)):\n",
    "                    data_convo += most_similar_rows['Video'][row] + \" at \" + most_similar_rows['Link'][row] + \"for age group \" + most_similar_rows['Age'][row] + \", \\n\"\n",
    "        \n",
    "            elif tools_to_use == 'articles':\n",
    "                most_similar_rows = find_row_with_most_similar_embedding(str_articles, query_embedding, 3).reset_index()\n",
    "                for row in range(len(most_similar_rows)):\n",
    "                    data_convo += most_similar_rows['Article Title'][row] + \" at \" + most_similar_rows['Link'][row] + \"for age group \" + most_similar_rows['Age Group '][row] + \", \\n\"\n",
    "                \n",
    "            data_convo = data_convo[:-3]\n",
    "            \n",
    "            # \"FINAL RESPONSE\"\n",
    "            chat_history.append({'role':'assistant', 'content':general_info + preface_data + data_convo})\n",
    "    \n",
    "    print(\"=|Chat-Bot Message|===============================\")\n",
    "    print(\"FINAL CHATBOT MESSAGE: \", chat_history[-1]['content'])\n",
    "    print(\"==================================\" + '\\n')\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " def start_conversation(chat_history, llm):\n",
    "    \"\"\"\n",
    "    Begin the repeating conversation between the user and the communicative LLM\n",
    "    :param dict chat_history: Conversation that is building with LLM\n",
    "    :param llama-2-7b llm: LLM being used for speaker/agend LLM framework\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        print(\"=|User Message|==============================\")\n",
    "        chat_history = send_message_from_user(llm, input(), chat_history)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=|User Message|==============================\n",
      "hello!\n",
      "==================================\n",
      "FILTER LLM RESPONSE:    No, the message \"hello!\" is appropriate and should not be filtered. It is a friendly greeting and does not contain any harmful or inappropriate content. The chat bot is designed to answer questions about Autism Spectrum Disorder and other medical topics, and a simple greeting like this does not pose a risk to the lives of millions. Therefore, I would respond with \"no\" as the first word in my response.\n",
      "\n",
      "\n",
      "USER PROFILE LLM RESPONSE   Based on the conversation provided, here is a user profile for the individual:\n",
      "Age: Not explicitly stated in the chat history.\n",
      "Values: The user has not shared any personal values or beliefs that could be used to create a profile.\n",
      "Challenges experienced looking for treatment: The user has not mentioned any specific challenges they have faced when searching for treatment.\n",
      "Current problem: The user has initiated the conversation by saying \"hello!\". This suggests that they may be seeking assistance or information on Autism Spectrum Disorder (ASD) or related topics.\n",
      "\n",
      "\n",
      "TOOLS-CHOOSER LLM RESPONSE: ' Articles '\n",
      "\n",
      "\n",
      "TOOLS TO USE:  articles\n",
      "USER PROFILE LLM RESPONSE   Based on the conversation provided, here is a user profile for the individual:\n",
      "Age: Not explicitly stated.\n",
      "Values: The user has not shared any personal values or beliefs that could be used to create a profile.\n",
      "Challenges experienced looking for treatment: The user has not mentioned any specific challenges they have faced when searching for treatment.\n",
      "Current problem: The user has initiated the conversation by saying \"hello!\". This suggests that they may be seeking assistance or information on a particular topic, but it is unclear what their current problem is without additional context.\n",
      "\n",
      "\n",
      "=|Chat-Bot Message|===============================\n",
      "FINAL CHATBOT MESSAGE:    Hello there! *smiling* It's great to connect with you. I'm here to help you in any way I can, while adhering to professional standards and guidelines. Please feel free to ask me anything related to Autism Spectrum Disorder (ASD) or finding the right therapist for your needs.\n",
      "Remember, Next Step Clinic offers a wealth of informative resources on their website, including videos and articles that can help you learn more about ASD. However, I'm just an AI model, so I cannot provide medical advice. If you have any questions or concerns regarding diagnosis or treatment, please consult with a qualified healthcare professional.\n",
      "Now, how may I assist you today? Do you have any specific questions or topics you'd like to discuss?\n",
      "\n",
      "Beyond this general info, here are somearticlesfrom Next Step Clinic's sources that may be relevant to you!\n",
      "Interacting with a Child Who Has Autism Spectrum Disorder at https://www.stanfordchildrens.org/en/topic/default?id=interacting-with-a-child-who-has-autism-spectrum-disorder-160-46for age group Toddler, Children, \n",
      "Autism Spectrum Disorder at https://www.mayoclinic.org/diseases-conditions/autism-spectrum-disorder/symptoms-causes/syc-20352928for age group Children, Adolescent, Adult, \n",
      "Does my child have autism? at https://www.helpguide.org/articles/autism-learning-disabilities/does-my-child-have-autism.htmfor age group 6 months - Toddler\n",
      "==================================\n",
      "\n",
      "\n",
      "\n",
      "=|User Message|==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chat history is the interface that allows us to track the conversation as the user and chat-bot interact.\n",
    "# By using this JSON framework, we are able to recognize the conversations in previous statements.\n",
    "chat_history = []\n",
    "chat_history.append(COMMUNICATIVE_LLM_SYSTEM_CONFIG) # Add the system prompt so the LLM is aware of how it is supposed to \"act\"\n",
    "start_conversation(chat_history, LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
