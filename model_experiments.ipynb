{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commodity Food Pricing: Model Experiments\n",
    "\n",
    "**By:** `MSOE AI-Club \"Nourish\" Student Research Team`<br/>\n",
    "**Primary Notebook Developer:** Ben Paulson, ____\n",
    "\n",
    "**Notebook Purpose:** To explore the use of machine learning to predict the price of commodities in the food industry. By utilizing the clean datasets loaded from `data_analysis.ipynb` into the directory `model_data`, we can begin to explore the use of machine learning to predict the price of commodities in the food industry. This notebook will be divided into sections of varying complexity, each of which will explore a different model type and its performance on the data. The models will be evaluated based on their ability to predict the price of a commodity in the future, given a set of features. The features will be selected based on their correlation to the price of the commodity, as determined in `data_analysis.ipynb`. There is also significant documentation with each section for both code/purpose sanity, sake of future reproducibility, and to help other members of the `MSOE AI-Club \"Nourish\" Student Research Team` understand the code and its purpose.\n",
    "* **Part 1: Building Complex ML Models**\n",
    "    * **Model 1:** Simple, 1-layer Transformer\n",
    "    * **Model 2:** ...\n",
    "* **Part 2: Experimenting with ML Models**\n",
    "    * **Experiment 1:** Using Only Previous Price Data With a Simple Transformer\n",
    "    * **Experiment 2:** ...\n",
    "\n",
    "**Research Context:** This research is being conducted as part of the MSOE AI-Club's \"Nourish\" project, which aims to use machine learning to predict future food prices in order to help farmers in developing countries make better decisions about food storage and crop selection, achieved through the accurate warning administration and prediction of food commodity pricing data by country and food market. This project is pending as part of a relationship with the United Nation's Food and Agriculture Organization (FAO). [FAO Official Statement on the Importance of Research Like This](https://youtu.be/sZx3hhnEHiI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\paulsonb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Proteus2</th>\n",
       "      <th>Food Price Index</th>\n",
       "      <th>Cereals Price Index</th>\n",
       "      <th>Wheat Futures</th>\n",
       "      <th>Harvest</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.351207</td>\n",
       "      <td>0.252506</td>\n",
       "      <td>0.647473</td>\n",
       "      <td>0.540047</td>\n",
       "      <td>405.90625</td>\n",
       "      <td>2679728.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.351207</td>\n",
       "      <td>0.252506</td>\n",
       "      <td>0.647473</td>\n",
       "      <td>0.540047</td>\n",
       "      <td>405.90625</td>\n",
       "      <td>23367493.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>0.351207</td>\n",
       "      <td>0.252506</td>\n",
       "      <td>0.647473</td>\n",
       "      <td>0.540047</td>\n",
       "      <td>405.90625</td>\n",
       "      <td>2157181.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.368768</td>\n",
       "      <td>0.252506</td>\n",
       "      <td>0.651951</td>\n",
       "      <td>0.538869</td>\n",
       "      <td>408.40625</td>\n",
       "      <td>2679728.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>0.368768</td>\n",
       "      <td>0.252506</td>\n",
       "      <td>0.651951</td>\n",
       "      <td>0.538869</td>\n",
       "      <td>408.40625</td>\n",
       "      <td>23367493.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>787</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.292393</td>\n",
       "      <td>0.476008</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>428.25000</td>\n",
       "      <td>3653782.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>788</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.292393</td>\n",
       "      <td>0.476008</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>428.25000</td>\n",
       "      <td>6109417.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>789</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.292393</td>\n",
       "      <td>0.476008</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>428.25000</td>\n",
       "      <td>31861336.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>790</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.292393</td>\n",
       "      <td>0.476008</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>428.25000</td>\n",
       "      <td>1994419.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>791</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.292393</td>\n",
       "      <td>0.476008</td>\n",
       "      <td>0.490577</td>\n",
       "      <td>428.25000</td>\n",
       "      <td>2941294.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        Date     Price  Proteus2  Food Price Index  \\\n",
       "0             0  2016-12-01  0.351207  0.252506          0.647473   \n",
       "1             1  2016-12-01  0.351207  0.252506          0.647473   \n",
       "2             2  2016-12-01  0.351207  0.252506          0.647473   \n",
       "3             3  2016-11-01  0.368768  0.252506          0.651951   \n",
       "4             4  2016-11-01  0.368768  0.252506          0.651951   \n",
       "..          ...         ...       ...       ...               ...   \n",
       "787         787  2002-11-01  0.284833  0.292393          0.476008   \n",
       "788         788  2002-11-01  0.284833  0.292393          0.476008   \n",
       "789         789  2002-11-01  0.284833  0.292393          0.476008   \n",
       "790         790  2002-11-01  0.284833  0.292393          0.476008   \n",
       "791         791  2002-11-01  0.284833  0.292393          0.476008   \n",
       "\n",
       "     Cereals Price Index  Wheat Futures     Harvest  Sentiment  \n",
       "0               0.540047      405.90625   2679728.0        1.0  \n",
       "1               0.540047      405.90625  23367493.0        1.0  \n",
       "2               0.540047      405.90625   2157181.0        1.0  \n",
       "3               0.538869      408.40625   2679728.0        1.0  \n",
       "4               0.538869      408.40625  23367493.0        1.0  \n",
       "..                   ...            ...         ...        ...  \n",
       "787             0.490577      428.25000   3653782.0        1.0  \n",
       "788             0.490577      428.25000   6109417.0        1.0  \n",
       "789             0.490577      428.25000  31861336.0        1.0  \n",
       "790             0.490577      428.25000   1994419.0        1.0  \n",
       "791             0.490577      428.25000   2941294.0        1.0  \n",
       "\n",
       "[792 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the data we hope to use throughout this experiment\n",
    "\n",
    "model_data = pd.read_csv('model_data/argentina_wheat_model_data.csv')\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building Complex ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define positional encoding function (another portion for data preprocessing)\n",
    "def positional_encoding(length, depth):\n",
    "    \"\"\" \n",
    "    Create positional encoding\n",
    "    args:\n",
    "        length: length of the sequence\n",
    "        depth: depth of the model\n",
    "    \"\"\"\n",
    "    pos_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / depth) for j in range(depth)]\n",
    "        for pos in range(length)\n",
    "    ])\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])\n",
    "    return tf.cast(pos_enc, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Simple, 1-Layer Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_SIZE = 64\n",
    "NUM_HEADS = 16\n",
    "FF_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-Head Attention\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = tf.keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    # Add & Norm\n",
    "    res = x + inputs  # Skip connection\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    \n",
    "    # Feed-Forward Network (Using Dense layers instead of Conv1D layers)\n",
    "    x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    \n",
    "    # Final Skip Connection\n",
    "    x = x + res  # Skip connection\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer\n",
    "inputs = tf.keras.Input(shape=(sequence_length, d_model))\n",
    "\n",
    "# Add positional encoding to the input\n",
    "# The positional encoding is added to the input in order to give the model some information about the relative position of the words in the sequence\n",
    "# Not including the positional encoding is basically the same as randomizing the order of the data\n",
    "x = inputs + positional_encoding(sequence_length, d_model) \n",
    "\n",
    "# Transformer Encoder\n",
    "x = transformer(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim)\n",
    "\n",
    "# Global Average Pooling layer\n",
    "# The Global Average Pooling layer reduces the dimensionality of the data\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
