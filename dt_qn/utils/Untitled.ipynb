{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers.time_limit import TimeLimit\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "\n",
    "try:\n",
    "    from gym_gridverse.gym import GymEnvironment\n",
    "    from gym_gridverse.envs.yaml.factory import factory_env_from_yaml\n",
    "    from gym_gridverse.outer_env import OuterEnv\n",
    "    from gym_gridverse.representations.observation_representations import (\n",
    "        make_observation_representation,\n",
    "    )\n",
    "    from gym_gridverse.representations.state_representations import (\n",
    "        make_state_representation,\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\n",
    "        f\"WARNING: ``gym_gridverse`` is not installed. This means you cannot run an experiment with the `gv_*` domains.\"\n",
    "    )\n",
    "    GymEnvironment = None\n",
    "from envs.gv_wrapper import GridVerseWrapper\n",
    "import os\n",
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "\n",
    "from utils.random import RNG\n",
    "\n",
    "\n",
    "def make_env(id_or_path: str) -> GymEnvironment:\n",
    "    \"\"\"Makes a GV gym environment.\"\"\"\n",
    "    try:\n",
    "        print(\"Loading using gym.make\")\n",
    "        env = gym.make(id_or_path)\n",
    "\n",
    "    except gym.error.Error:\n",
    "        print(f\"Environment with id {id_or_path} not found.\")\n",
    "        print(\"Loading using YAML\")\n",
    "        inner_env = factory_env_from_yaml(\n",
    "            os.path.join(os.getcwd(), \"envs\", \"gridverse\", id_or_path)\n",
    "        )\n",
    "        state_representation = make_state_representation(\n",
    "            \"default\", inner_env.state_space\n",
    "        )\n",
    "        observation_representation = make_observation_representation(\n",
    "            \"default\", inner_env.observation_space\n",
    "        )\n",
    "        outer_env = OuterEnv(\n",
    "            inner_env,\n",
    "            state_representation=state_representation,\n",
    "            observation_representation=observation_representation,\n",
    "        )\n",
    "        env = GymEnvironment(outer_env)\n",
    "        env = TimeLimit(GridVerseWrapper(env), max_episode_steps=250)\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "class ObsType(Enum):\n",
    "    DISCRETE = 0\n",
    "    CONTINUOUS = 1\n",
    "    IMAGE = 2\n",
    "\n",
    "\n",
    "def get_env_obs_type(env: gym.Env) -> int:\n",
    "    obs_space = env.observation_space\n",
    "    sample_obs = env.reset()\n",
    "    # Check for image first\n",
    "    if (\n",
    "        (isinstance(sample_obs, np.ndarray) and len(sample_obs.shape) == 3)\n",
    "        and isinstance(obs_space, spaces.Box)\n",
    "        and np.all(obs_space.low == 0)\n",
    "        and np.all(obs_space.high == 255)\n",
    "    ):\n",
    "        return ObsType.IMAGE\n",
    "    elif isinstance(\n",
    "        obs_space, (spaces.Discrete, spaces.MultiDiscrete, spaces.MultiBinary)\n",
    "    ):\n",
    "        return ObsType.DISCRETE\n",
    "    else:\n",
    "        return ObsType.CONTINUOUS\n",
    "\n",
    "\n",
    "def get_env_obs_length(env: gym.Env) -> int:\n",
    "    \"\"\"Gets the length of the observations in an environment\"\"\"\n",
    "    if get_env_obs_type(env) == ObsType.IMAGE:\n",
    "        return env.reset().shape\n",
    "    elif isinstance(env.observation_space, gym.spaces.Discrete):\n",
    "        return 1\n",
    "    elif isinstance(env.observation_space, (gym.spaces.MultiDiscrete, gym.spaces.Box)):\n",
    "        if len(env.observation_space.shape) != 1:\n",
    "            raise NotImplementedError(f\"We do not yet support 2D observation spaces\")\n",
    "        return env.observation_space.shape[0]\n",
    "    elif isinstance(env.observation_space, spaces.MultiBinary):\n",
    "        return env.observation_space.n\n",
    "    else:\n",
    "        raise NotImplementedError(f\"We do not yet support {env.observation_space}\")\n",
    "\n",
    "\n",
    "def get_env_obs_mask(env: gym.Env) -> Union[int, np.ndarray]:\n",
    "    \"\"\"Gets the number of observations possible (for discrete case).\n",
    "    For continuous case, please edit the -5 to something lower than\n",
    "    lowest possible observation (while still being finite) so the\n",
    "    network knows it is padding.\n",
    "    \"\"\"\n",
    "    # Check image first\n",
    "    if get_env_obs_type(env) == ObsType.IMAGE:\n",
    "        return 0\n",
    "    if isinstance(env.observation_space, gym.spaces.Discrete):\n",
    "        return env.observation_space.n\n",
    "    elif isinstance(env.observation_space, gym.spaces.MultiDiscrete):\n",
    "        return max(env.observation_space.nvec) + 1\n",
    "    elif isinstance(env.observation_space, gym.spaces.Box):\n",
    "        # If you would like to use DTQN with a continuous action space, make sure this value is\n",
    "        #       below the minimum possible observation. Otherwise it will appear as a real observation\n",
    "        #       to the network which may cause issues. In our case, Car Flag has min of -1 so this is\n",
    "        #       fine.\n",
    "        return -5\n",
    "    else:\n",
    "        raise NotImplementedError(f\"We do not yet support {env.observation_space}\")\n",
    "\n",
    "\n",
    "def get_env_max_steps(env: gym.Env) -> Union[int, None]:\n",
    "    \"\"\"Gets the maximum steps allowed in an episode before auto-terminating\"\"\"\n",
    "    try:\n",
    "        return env._max_episode_steps\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            return env.max_episode_steps\n",
    "        except AttributeError:\n",
    "            return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
