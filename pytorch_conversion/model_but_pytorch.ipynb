{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Git\\Predicting-Commodity-Food-Pricing\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import data_loading as dl\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading the Experiment(s) Data\n",
    "Based on the data retrieved from `data_analysis.ipynb`, get that data into a format capable of being used by a Machine Learning model.\n",
    "\n",
    "<span style=\"color: orange;\">**Future Experiment:** Generating multiple months or simply estimating a year in advance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DATA_DIRECTORY = '../model_data/wheat_model_data/'\n",
    "TEST_SIZE = 0.2\n",
    "OUTPUT_COLUMN_NAME = 'Price'\n",
    "\n",
    "# Model Architecture\n",
    "SEQ_LEN = 3\n",
    "HEAD_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 16\n",
    "\n",
    "# ML Optimizer\n",
    "LEARNING_RATE = 1e-3\n",
    "CLIP_VALUE = 0.5 # Gradient Clipping (https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem)\n",
    "DROP_OUT_RATE = 0.2\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 1 \n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "d_model = NUM_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features for this model (given the model_data chosen)\n",
    "sample_file_path = os.path.join(MODEL_DATA_DIRECTORY, os.listdir(MODEL_DATA_DIRECTORY)[0])\n",
    "sample_columns = pd.read_csv(sample_file_path).columns[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Git\\Predicting-Commodity-Food-Pricing\\pytorch_conversion\\data_loading.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_data = pd.concat([model_data, data_to_concat], ignore_index=True).drop(columns=['Unnamed: 0'])\n"
     ]
    }
   ],
   "source": [
    "model_data = dl.get_data_from_dir(MODEL_DATA_DIRECTORY, sample_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Price', 'Proteus2', 'Food Price Index', 'Cereals Price Index',\n",
       "       'Wheat Futures', 'Harvest', 'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_tensor.shape: torch.Size([721, 3, 5])\n",
      "y_train_tensor.shape: torch.Size([721, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs_and_outputs = model_data.apply(dl.div_inputs_and_outputs, axis=1)\n",
    "inputs = inputs_and_outputs['inputs'].tolist(); outputs = inputs_and_outputs['output'].tolist()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, outputs, test_size=TEST_SIZE, shuffle=False) \n",
    "\n",
    "x_train_tensor, x_test_tensor, y_train_tensor, y_test_tensor = dl.format_for_ML_usage_torch(inputs, outputs)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_data = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Print the shapes of the data\n",
    "print(f\"x_train_tensor.shape: {x_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor.shape: {y_train_tensor.shape}\")\n",
    "\n",
    "num_features = x_train_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building Complex ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Simple, 1-Layer Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Create a long enough positional encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # Register as a buffer that is not a model parameter\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'x: {x}')  \n",
    "        pe = self.pe[:x.size(1), :] \n",
    "        pe = pe.reshape(1, pe.shape[0], pe.shape[1])\n",
    "        pe_reshaped = pe.repeat(1, 3, 1)  # Repeats the tensor to shape [1, 3, 8]\n",
    "        result = x + pe_reshaped  # Adds the reshaped pe to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, head_size, num_heads, ff_dim, dropout=0):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout)\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=ff_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=ff_dim, out_channels=d_model, kernel_size=1)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # Note: MultiheadAttention expects input of shape (L, N, E) where L is the sequence length, N is the batch size, and E is the embedding dimension.\n",
    "        attn_output, _ = self.attention(query, key, value)\n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        \n",
    "        # Conv1D layers expect input of shape (N, C, L), hence we permute\n",
    "        out1_permuted = out1.permute(1, 2, 0)\n",
    "        ff_output = F.relu(self.conv1(out1_permuted))\n",
    "        ff_output = self.conv2(ff_output)\n",
    "        \n",
    "        # Permute back to match the MultiheadAttention output shape\n",
    "        ff_output = ff_output.permute(2, 0, 1)\n",
    "        out2 = self.layernorm2(out1 + self.dropout(ff_output))\n",
    "        \n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, seq_len, num_features, d_model, head_size, num_heads, ff_dim, dropout=0, num_transformers=10):\n",
    "        super(TransformerModel, self).__init__()  \n",
    "        self.seq_len = seq_len\n",
    "        self.num_features = num_features\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = nn.Linear(num_features, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, seq_len)\n",
    "        self.transformers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, head_size, num_heads, ff_dim, dropout) \n",
    "            for _ in range(num_transformers)\n",
    "        ])\n",
    "        # Output layer now directly maps the d_model features to a single output value\n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'Shape of input: {x.shape}')\n",
    "        if x.size(1) != self.seq_len:\n",
    "            raise ValueError(f\"Expected sequence length {self.seq_len}, but got {x.size(1)}\")\n",
    "        x = self.input_projection(x)  \n",
    "        # print(f'Shape of input after input projection: {x.shape}')\n",
    "        x = self.pos_encoding(x) \n",
    "        print(f'Shape of input after positional encoding: {x.shape}')\n",
    "        for transformer in self.transformers:\n",
    "            x = transformer(x, x, x)  # Process through transformer blocks\n",
    "        # print(f'Shape of output from transformers: {x.shape}')\n",
    "        x = x[:, -1, :]  \n",
    "        # print(f'Shape of output after taking last sequence: {x.shape}')\n",
    "        x = self.output_layer(x) \n",
    "        # print(f'Shape of output after output layer: {x.shape}')\n",
    "        # print()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "model = TransformerModel(seq_len=SEQ_LEN, num_features=num_features, d_model=d_model, head_size=HEAD_SIZE, num_heads=NUM_HEADS, ff_dim=FF_DIM, dropout=DROP_OUT_RATE)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the Model\n",
    "This section is specifically for training the model built in the previous section. Some contants (`NUM_EPOCHS`, `BATCH_SIZE`) are provided and should be the only required parameters to adjust for this section of the experiment. \n",
    "\n",
    "A plot of the loss throughout the training process is provided for easy understanding about if the model is overfitting or underfitting. For a review of these concepts, see [this article](https://www.analyticsfordecisions.com/overfitting-and-underfitting/#:~:text=Overfitting%20happens%20when%20the%20model%20is%20too%20complex,poor%20performance%20on%20both%20training%20and%20test%20datasets.).\n",
    "<br/><br/>\n",
    "**Potential Future Parameters**\n",
    "* **Regularization:** L1, L2, Dropout; helps prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learning_rate_scheduler(epoch, lr):\n",
    "#     \"\"\"\n",
    "#     Learning rate scheduler\n",
    "#     :param int epoch: current epoch\n",
    "#     :param float lr: current learning rate\n",
    "#     \"\"\"\n",
    "#     if epoch < 15:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "# callback = LearningRateScheduler(learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n",
      "Shape of input after positional encoding: torch.Size([3, 3, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     26\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 27\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     28\u001b[0m     epoch_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train_loss) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m train_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m train_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[115], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Git\\Predicting-Commodity-Food-Pricing\\.venv\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Git\\Predicting-Commodity-Food-Pricing\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Training function doesn't need major changes, but be mindful of the input and output dimensions during training\n",
    "def train(model, data_loader, optimizer, criterion):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for batch, (input, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(input)\n",
    "        if target.dim() > 1:\n",
    "            target = target.squeeze()  # Adjust this based on the actual shape of your targets\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Training loop\n",
    "train_loss = []\n",
    "happy = ':)'\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss.append(train(model, train_loader, optimizer, criterion))\n",
    "    epoch_end_time = time.time()\n",
    "    if len(train_loss) > 1 and train_loss[-1] < train_loss[-2]:\n",
    "        happy = ':)'\n",
    "    elif len(train_loss) > 1 and train_loss[-1] >= train_loss[-2]:\n",
    "        happy = ':('\n",
    "    print(f'| epoch {epoch:3d} | train_loss {train_loss[-1]:5.2f} {happy} | time {epoch_end_time - epoch_start_time:5.2f} sec | ETA {((epoch_end_time - epoch_start_time) * (NUM_EPOCHS - epoch)) / 60:5.2f} min |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over time\n",
    "plt.plot(train_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model   \n",
    "# torch.save(model.state_dict(), '../saved_models/transformer_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Examining Results\n",
    "In this section, we're plotting the model's predictions versus the actual price point for the commodity in question. However, one plot focuses specifically on the testing data only (this is a better plot to see how well the model is performing/generalizing) and the other focuses on the entire dataset (this is a better plot to see if the model is correlating to the provided dataset at all).\n",
    "\n",
    "Therefore, when **evaluating the performance** of the model, **the first plot should be used.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (543,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mismatch in number of samples: y_test_tensor has 181 samples, predictions_tensor has 543 samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure y_test_tensor and predictions_tensor have the same number of samples\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# This step is crucial to avoid dimension mismatch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y_test_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in number of samples: y_test_tensor has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, predictions_tensor has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test example:\u001b[39m\u001b[38;5;124m'\u001b[39m, y_test[:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions example:\u001b[39m\u001b[38;5;124m'\u001b[39m, predictions[:\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: Mismatch in number of samples: y_test_tensor has 181 samples, predictions_tensor has 543 samples"
     ]
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(x_test_tensor), BATCH_SIZE):\n",
    "        batch = x_test_tensor[i:i+BATCH_SIZE]\n",
    "        preds = model(batch)\n",
    "        preds = preds.squeeze().tolist()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Ensure predictions are in the correct shape\n",
    "# Flatten or reshape predictions to match the target's shape\n",
    "print('predictions shape:', np.array(predictions).shape)\n",
    "predictions_tensor = torch.tensor(predictions, dtype=torch.float32)\n",
    "\n",
    "# Ensure y_test_tensor and predictions_tensor have the same number of samples\n",
    "# This step is crucial to avoid dimension mismatch\n",
    "if predictions_tensor.shape[0] != y_test_tensor.shape[0]:\n",
    "    raise ValueError(f\"Mismatch in number of samples: y_test_tensor has {y_test_tensor.shape[0]} samples, predictions_tensor has {predictions_tensor.shape[0]} samples\")\n",
    "\n",
    "print('y_test example:', y_test[:10])\n",
    "print('predictions example:', predictions[:10])\n",
    "print('y_test shape:', y_test_tensor.shape)\n",
    "print('predictions shape:', predictions_tensor.shape)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_tensor.numpy().flatten(), label='Actual')\n",
    "plt.plot(predictions_tensor.numpy().flatten(), label='Predicted')\n",
    "plt.title('Model Predictions (Testing Data Only)')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Months')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Mean Absolute Error\n",
    "final_mae = mean_absolute_error(y_test_tensor.numpy(), predictions_tensor.numpy())\n",
    "print('Mean Absolute Error (FINAL ACCURACY METRIC):', final_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to saved_models\n",
    "model.save(f'saved_models/wheat_price_transformer_model_{final_mae}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
