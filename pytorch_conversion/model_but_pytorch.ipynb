{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import data_loading as dl\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading the Experiment(s) Data\n",
    "Based on the data retrieved from `data_analysis.ipynb`, get that data into a format capable of being used by a Machine Learning model.\n",
    "\n",
    "<span style=\"color: orange;\">**Future Experiment:** Generating multiple months or simply estimating a year in advance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DATA_DIRECTORY = '../model_data/wheat_model_data/'\n",
    "TEST_SIZE = 0.2\n",
    "OUTPUT_COLUMN_NAME = 'Price'\n",
    "\n",
    "# Model Architecture\n",
    "SEQ_LEN = 3\n",
    "HEAD_SIZE = 64\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 16\n",
    "\n",
    "# ML Optimizer\n",
    "LEARNING_RATE = 1e-3\n",
    "CLIP_VALUE = 0.5 # Gradient Clipping (https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem)\n",
    "DROP_OUT_RATE = 0.2\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 1 \n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "d_model = NUM_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features for this model (given the model_data chosen)\n",
    "sample_file_path = os.path.join(MODEL_DATA_DIRECTORY, os.listdir(MODEL_DATA_DIRECTORY)[0])\n",
    "sample_columns = pd.read_csv(sample_file_path).columns[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sydneybalboni/Documents/GitHub/Predicting-Commodity-Food-Pricing/pytorch_conversion/data_loading.py:200: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  model_data = pd.concat([model_data, data_to_concat], ignore_index=True).drop(columns=['Unnamed: 0'])\n"
     ]
    }
   ],
   "source": [
    "model_data = dl.get_data_from_dir(MODEL_DATA_DIRECTORY, sample_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Price', 'Proteus2', 'Food Price Index', 'Cereals Price Index',\n",
       "       'Wheat Futures', 'Harvest', 'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_tensor.shape: torch.Size([721, 3, 5])\n",
      "y_train_tensor.shape: torch.Size([721, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs_and_outputs = model_data.apply(dl.div_inputs_and_outputs, axis=1)\n",
    "inputs = inputs_and_outputs['inputs'].tolist(); outputs = inputs_and_outputs['output'].tolist()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, outputs, test_size=TEST_SIZE, shuffle=False) \n",
    "\n",
    "x_train_tensor, x_test_tensor, y_train_tensor, y_test_tensor = dl.format_for_ML_usage_torch(inputs, outputs)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_data = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Print the shapes of the data\n",
    "print(f\"x_train_tensor.shape: {x_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor.shape: {y_train_tensor.shape}\")\n",
    "\n",
    "num_features = x_train_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building Complex ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Simple, 1-Layer Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Create a long enough positional encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # Shape: [max_len, 1, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pe = self.pe[:x.size(1), :].expand(-1, x.size(0), -1)  \n",
    "        pe = pe.transpose(0, 1) \n",
    "        return x + pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, head_size, num_heads, ff_dim, dropout=0):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, dropout=dropout)\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=ff_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=ff_dim, out_channels=d_model, kernel_size=1)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # MultiheadAttention expects input of shape (L, N, E) where L is the sequence length, N is the batch size, and E is the embedding dimension.\n",
    "        attn_output, _ = self.attention(query, key, value)\n",
    "        out1 = self.layernorm1(query + attn_output)\n",
    "        \n",
    "        # Conv1D layers expect input of shape (N, C, L), hence we permute\n",
    "        out1_permuted = out1.permute(1, 2, 0)\n",
    "        ff_output = F.relu(self.conv1(out1_permuted))\n",
    "        ff_output = self.conv2(ff_output)\n",
    "        \n",
    "        # Permute back to match the MultiheadAttention output shape\n",
    "        ff_output = ff_output.permute(2, 0, 1)\n",
    "        out2 = self.layernorm2(out1 + self.dropout(ff_output))\n",
    "        \n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, seq_len, num_features, d_model, head_size, num_heads, ff_dim, dropout=0, num_transformers=10):\n",
    "        super(TransformerModel, self).__init__()  \n",
    "        self.seq_len = seq_len\n",
    "        self.num_features = num_features\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = nn.Linear(num_features, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, seq_len)\n",
    "        self.transformers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, head_size, num_heads, ff_dim, dropout) \n",
    "            for _ in range(num_transformers)\n",
    "        ])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.size(1) != self.seq_len:\n",
    "            raise ValueError(f\"Expected sequence length {self.seq_len}, but got {x.size(1)}\")\n",
    "\n",
    "        x = self.input_projection(x)  # Projects input to d_model dimensions\n",
    "        x = self.pos_encoding(x)  # Apply positional encoding\n",
    "\n",
    "        for transformer in self.transformers:\n",
    "            x = transformer(x, x, x)  # Process through transformer blocks\n",
    "\n",
    "        # Reduce the sequence of transformed features to a single feature vector\n",
    "        x = x.mean(dim=1)  # Average over the sequence dimension\n",
    "\n",
    "        # Now x has shape [batch_size, d_model]\n",
    "\n",
    "        # Pass the feature vector through the output layer to get the final scalar prediction\n",
    "        x = self.output_layer(x)  # Now x has shape [batch_size, 1]\n",
    "        \n",
    "        # Squeeze the last dimension so we get a 1D tensor of shape [batch_size],\n",
    "        # where each item is the scalar prediction for the corresponding sequence\n",
    "        x = x.squeeze(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "model = TransformerModel(seq_len=SEQ_LEN, num_features=num_features, d_model=d_model, head_size=HEAD_SIZE, num_heads=NUM_HEADS, ff_dim=FF_DIM, dropout=DROP_OUT_RATE)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the Model\n",
    "This section is specifically for training the model built in the previous section. Some contants (`NUM_EPOCHS`, `BATCH_SIZE`) are provided and should be the only required parameters to adjust for this section of the experiment. \n",
    "\n",
    "A plot of the loss throughout the training process is provided for easy understanding about if the model is overfitting or underfitting. For a review of these concepts, see [this article](https://www.analyticsfordecisions.com/overfitting-and-underfitting/#:~:text=Overfitting%20happens%20when%20the%20model%20is%20too%20complex,poor%20performance%20on%20both%20training%20and%20test%20datasets.).\n",
    "<br/><br/>\n",
    "**Potential Future Parameters**\n",
    "* **Regularization:** L1, L2, Dropout; helps prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learning_rate_scheduler(epoch, lr):\n",
    "#     \"\"\"\n",
    "#     Learning rate scheduler\n",
    "#     :param int epoch: current epoch\n",
    "#     :param float lr: current learning rate\n",
    "#     \"\"\"\n",
    "#     if epoch < 15:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "# callback = LearningRateScheduler(learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train_loss  0.15 :) | time  9.73 sec | ETA  0.65 min |\n",
      "| epoch   2 | train_loss  0.14 :) | time  9.85 sec | ETA  0.49 min |\n",
      "| epoch   3 | train_loss  0.13 :) | time  9.64 sec | ETA  0.32 min |\n",
      "| epoch   4 | train_loss  0.13 :) | time 10.06 sec | ETA  0.17 min |\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Training function doesn't need major changes, but be mindful of the input and output dimensions during training\n",
    "def train(model, data_loader, optimizer, criterion):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for batch, (input, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(input)\n",
    "        # Squeeze the output to remove unnecessary dimensions\n",
    "        output = output.squeeze()  # This changes shape from [batch_size, 1, 1] to [batch_size]\n",
    "        # Ensure target is the correct shape. If necessary, reshape or squeeze.\n",
    "        if target.dim() > 1:\n",
    "            target = target.squeeze()  # Adjust this based on the actual shape of your targets\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Training loop\n",
    "train_loss = []\n",
    "happy = ':)'\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss.append(train(model, train_loader, optimizer, criterion))\n",
    "    epoch_end_time = time.time()\n",
    "    if len(train_loss) > 1 and train_loss[-1] < train_loss[-2]:\n",
    "        happy = ':)'\n",
    "    elif len(train_loss) > 1 and train_loss[-1] >= train_loss[-2]:\n",
    "        happy = ':('\n",
    "    print(f'| epoch {epoch:3d} | train_loss {train_loss[-1]:5.2f} {happy} | time {epoch_end_time - epoch_start_time:5.2f} sec | ETA {((epoch_end_time - epoch_start_time) * (NUM_EPOCHS - epoch)) / 60:5.2f} min |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss over time\n",
    "plt.plot(train_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Examining Results\n",
    "In this section, we're plotting the model's predictions versus the actual price point for the commodity in question. However, one plot focuses specifically on the testing data only (this is a better plot to see how well the model is performing/generalizing) and the other focuses on the entire dataset (this is a better plot to see if the model is correlating to the provided dataset at all).\n",
    "\n",
    "Therefore, when **evaluating the performance** of the model, **the first plot should be used.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# No need to manually handle the batch indexing, DataLoader will provide the batches\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        preds = model(input)\n",
    "        preds = preds.tolist()\n",
    "        predictions.extend(preds)\n",
    "\n",
    "# Convert the list of predictions to a tensor for comparison with y_test_tensor\n",
    "predictions_tensor = torch.tensor(predictions, dtype=torch.float32)\n",
    "\n",
    "# Ensure predictions are in the correct shape\n",
    "print('predictions shape:', predictions_tensor.shape)\n",
    "\n",
    "# Ensure y_test_tensor and predictions_tensor have the same number of samples\n",
    "if predictions_tensor.shape[0] != y_test_tensor.shape[0]:\n",
    "    raise ValueError(f\"Mismatch in number of samples: y_test_tensor has {y_test_tensor.shape[0]} samples, predictions_tensor has {predictions_tensor.shape[0]} samples\")\n",
    "\n",
    "print('y_test example:', y_test[:10])\n",
    "print('predictions example:', predictions[:10])\n",
    "print('y_test shape:', y_test_tensor.shape)\n",
    "print('predictions shape:', predictions_tensor.shape)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_tensor.numpy().flatten(), label='Actual')\n",
    "plt.plot(predictions_tensor.numpy().flatten(), label='Predicted')\n",
    "plt.title('Model Predictions (Testing Data Only)')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Months')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the Mean Absolute Error\n",
    "final_mae = mean_absolute_error(y_test_tensor.numpy(), predictions_tensor.numpy())\n",
    "print('Mean Absolute Error (FINAL ACCURACY METRIC):', final_mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
